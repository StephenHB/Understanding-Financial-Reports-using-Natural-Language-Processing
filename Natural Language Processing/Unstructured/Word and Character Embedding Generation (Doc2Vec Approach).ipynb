{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/vvsaripalli/SECReports/Understanding-Financial-Reports-using-Natural-Language-Processing/Natural Language Processing/wordembeddings/lib/python3.5/site-packages\n",
      "gensim installed\n",
      "TensorFlow version: \t1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "import numpy\n",
    "import gensim\n",
    "import logging\n",
    "import sys, os\n",
    "import nltk\n",
    "import re, string, unicodedata\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time  # To time our operations\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "# */site-packages is where your current session is running its python out of\n",
    "site_path = ''\n",
    "for path in sys.path:\n",
    "    if 'site-packages' in path.split('/')[-1]:\n",
    "        print(path)\n",
    "        site_path = path\n",
    "# search to see if gensim in installed packages\n",
    "if len(site_path) > 0:\n",
    "    if not 'gensim' in os.listdir(site_path):\n",
    "        print('package not found')\n",
    "    else:\n",
    "        print('gensim installed')    \n",
    "        \n",
    "\n",
    "# Checking tensorflow installation\n",
    "print('TensorFlow version: \\t%s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining directories for reading text files and saving checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For displaying gensim logs\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Directory with raw txt-files\n",
    "TEXT_DIR  = 'Train/'\n",
    "\n",
    "# Directory for saving checkpoint and metadata\n",
    "MODEL_DIR = 'Checkpoints/'\n",
    "\n",
    "# Word2vec\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading all the text files in the corpus and tokeniztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    \"\"\"\n",
    "    Read in text files\n",
    "    \"\"\"\n",
    "    documents = list()\n",
    "    tokenize  = lambda x: simple_preprocess(x)\n",
    "    \n",
    "    # Read in all files in directory\n",
    "    if os.path.isdir(path):\n",
    "        for filename in os.listdir(path):\n",
    "            with open('%s/%s' % (path, filename), encoding='utf-8') as f:\n",
    "                doc = f.read()\n",
    "                doc = clean_doc(doc)\n",
    "                documents.append(tokenize(doc))\n",
    "    return documents\n",
    "\n",
    "def clean_doc(doc):\n",
    "    \"\"\"\n",
    "    Cleaning a document by several methods\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    doc = doc.lower()\n",
    "    # Remove numbers\n",
    "    doc = re.sub(r\"[0-9]+\", \"\", doc)\n",
    "    # Split in tokens\n",
    "    tokens = doc.split()\n",
    "    # Remove punctuation\n",
    "    tokens = [w.translate(str.maketrans('', '', string.punctuation)) for w in tokens]\n",
    "    # Tokens with less then two characters will be ignored\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 7855\n"
     ]
    }
   ],
   "source": [
    "docs = read_files(TEXT_DIR)\n",
    "print('Number of documents: %i' % len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training our Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the necessary hyperparameteres to tunr our word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now defining and training our Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : collected 49588 word types from a corpus of 33675431 raw words and 7855 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : effective_min_count=5 retains 24966 unique words (50% of original 49588, drops 24622)\n",
      "INFO : effective_min_count=5 leaves 33630646 word corpus (99% of original 33675431, drops 44785)\n",
      "INFO : deleting the raw counts dictionary of 49588 items\n",
      "INFO : sample=0.001 downsamples 59 most-common words\n",
      "INFO : downsampling leaves estimated 24932968 word corpus (74.1% of prior 33630646)\n",
      "INFO : estimated required memory for 24966 words and 300 dimensions: 72401400 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 3 workers on 24966 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO : EPOCH 1 - PROGRESS: at 3.09% examples, 657036 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 6.70% examples, 726325 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 10.50% examples, 749122 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 13.46% examples, 740571 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 17.11% examples, 752589 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 20.71% examples, 763220 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 24.52% examples, 773752 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 28.36% examples, 774990 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 32.13% examples, 775402 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 35.91% examples, 779896 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 39.06% examples, 767522 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 42.85% examples, 769306 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 46.82% examples, 777295 words/s, in_qsize 5, out_qsize 1\n",
      "INFO : EPOCH 1 - PROGRESS: at 50.96% examples, 781276 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 54.77% examples, 781562 words/s, in_qsize 4, out_qsize 1\n",
      "INFO : EPOCH 1 - PROGRESS: at 58.54% examples, 783938 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 62.19% examples, 786902 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 66.49% examples, 791210 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 70.55% examples, 794177 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 74.77% examples, 796557 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 78.28% examples, 797481 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 82.15% examples, 800141 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 86.01% examples, 800754 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 89.46% examples, 798175 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 93.63% examples, 799334 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 98.00% examples, 800782 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 33675431 raw words (21416605 effective words) took 26.8s, 798459 effective words/s\n",
      "INFO : EPOCH 2 - PROGRESS: at 3.97% examples, 835803 words/s, in_qsize 6, out_qsize 1\n",
      "INFO : EPOCH 2 - PROGRESS: at 7.52% examples, 840368 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 11.76% examples, 853141 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 15.40% examples, 844190 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 19.15% examples, 845195 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 22.48% examples, 831790 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 26.52% examples, 835798 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 30.60% examples, 831634 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 34.19% examples, 823560 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 38.06% examples, 826054 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 42.23% examples, 830349 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 46.09% examples, 832213 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 50.36% examples, 833580 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 53.94% examples, 827318 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 56.94% examples, 818479 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 60.87% examples, 820739 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 821580 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 68.50% examples, 818876 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 72.63% examples, 819981 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 76.77% examples, 821768 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 80.42% examples, 822413 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 84.52% examples, 824791 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 88.34% examples, 826044 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 92.65% examples, 827139 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 96.60% examples, 824671 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 33675431 raw words (21416527 effective words) took 25.9s, 825583 effective words/s\n",
      "INFO : EPOCH 3 - PROGRESS: at 3.21% examples, 688239 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 6.70% examples, 738831 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 10.64% examples, 774577 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 14.35% examples, 796582 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 18.15% examples, 807705 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 22.00% examples, 809966 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 25.50% examples, 808076 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 29.89% examples, 814309 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 33.63% examples, 814819 words/s, in_qsize 6, out_qsize 1\n",
      "INFO : EPOCH 3 - PROGRESS: at 37.72% examples, 819275 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 41.64% examples, 821158 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 45.28% examples, 820381 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 49.62% examples, 822660 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 53.84% examples, 826286 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 57.56% examples, 828939 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 61.53% examples, 831289 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 65.35% examples, 830304 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 68.81% examples, 824023 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 72.64% examples, 821340 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 76.77% examples, 822136 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 80.55% examples, 823836 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 84.53% examples, 825353 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 88.33% examples, 825717 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 91.75% examples, 820054 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 95.00% examples, 813231 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 99.49% examples, 814063 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 33675431 raw words (21419134 effective words) took 26.3s, 813930 effective words/s\n",
      "INFO : EPOCH 4 - PROGRESS: at 3.86% examples, 808815 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 7.50% examples, 837528 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 11.18% examples, 814573 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 14.74% examples, 812872 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 18.20% examples, 809635 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 22.08% examples, 814217 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 26.00% examples, 821046 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 30.40% examples, 824718 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 34.27% examples, 826127 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 37.30% examples, 808386 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 41.08% examples, 810519 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 45.05% examples, 813409 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 48.73% examples, 807459 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 52.77% examples, 811001 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 56.69% examples, 814537 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 60.71% examples, 817650 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 64.54% examples, 819516 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 68.40% examples, 817940 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 72.60% examples, 820112 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 819868 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 80.24% examples, 821345 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 84.10% examples, 819170 words/s, in_qsize 6, out_qsize 2\n",
      "INFO : EPOCH 4 - PROGRESS: at 87.52% examples, 815972 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 91.01% examples, 814195 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 95.20% examples, 813918 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 99.53% examples, 813970 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 33675431 raw words (21415014 effective words) took 26.3s, 813861 effective words/s\n",
      "INFO : EPOCH 5 - PROGRESS: at 3.49% examples, 743357 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 6.85% examples, 761948 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 10.67% examples, 775853 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 14.07% examples, 776998 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 17.67% examples, 777817 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 21.21% examples, 789273 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 25.04% examples, 799057 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 29.26% examples, 796701 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 32.55% examples, 789234 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 35.57% examples, 776221 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 39.16% examples, 773088 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 42.94% examples, 775615 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 46.82% examples, 781591 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 50.88% examples, 784099 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 54.87% examples, 786850 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 58.65% examples, 789530 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 61.57% examples, 783097 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 65.59% examples, 785370 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 69.54% examples, 786320 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 73.66% examples, 788856 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 77.29% examples, 788793 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 80.89% examples, 790642 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 84.88% examples, 792466 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 88.57% examples, 793884 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 92.65% examples, 794734 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 96.88% examples, 795945 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 33675431 raw words (21416967 effective words) took 26.9s, 796410 effective words/s\n",
      "INFO : training on a 168377155 raw words (107084247 effective words) took 132.4s, 809081 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(docs, size=EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our trained model as a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : saving Word2Vec object under Checkpoints/word2vec, separately None\n",
      "INFO : not storing attribute vectors_norm\n",
      "INFO : not storing attribute cum_table\n",
      "INFO : saved Checkpoints/word2vec\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "model.save(os.path.join(MODEL_DIR,'word2vec'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating metadata and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of weights: (24966, 300)\n",
      "Vocabulary size: 24966\n",
      "Embedding size: 300\n"
     ]
    }
   ],
   "source": [
    "weights     = model.wv.vectors\n",
    "index_words = model.wv.index2word\n",
    "\n",
    "vocab_size    = weights.shape[0]\n",
    "embedding_dim = weights.shape[1]\n",
    "\n",
    "print('Shape of weights:', weights.shape)\n",
    "print('Vocabulary size: %i' % vocab_size)\n",
    "print('Embedding size: %i'  % embedding_dim)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR,'metadata.tsv'), 'w') as f:\n",
    "    f.writelines(\"\\n\".join(index_words))\n",
    "\n",
    "# Required if you re-run without restarting the kernel\n",
    "tf.reset_default_graph()\n",
    "    \n",
    "W = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]), trainable=False, name=\"W\")\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n",
    "\n",
    "embedding_init = W.assign(embedding_placeholder)\n",
    "writer = tf.summary.FileWriter(MODEL_DIR, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = W.name\n",
    "embedding.metadata_path = './metadata.tsv'\n",
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(embedding_init, feed_dict={embedding_placeholder: weights})\n",
    "    save_path = saver.save(sess, os.path.join(MODEL_DIR, \"model.cpkt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sell', 0.5410637855529785),\n",
       " ('contractsbuy', 0.4904049038887024),\n",
       " ('issuersbuy', 0.47991445660591125),\n",
       " ('valuesell', 0.4697945713996887),\n",
       " ('contractssell', 0.4678630232810974),\n",
       " ('valuebuy', 0.46492916345596313),\n",
       " ('balancebuy', 0.45454537868499756),\n",
       " ('issuessold', 0.45103883743286133),\n",
       " ('indicessell', 0.45057427883148193),\n",
       " ('indicesbuy', 0.44925206899642944)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['buy'], topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
