{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/vvsaripalli/SECReports/Understanding-Financial-Reports-using-Natural-Language-Processing/Natural Language Processing/wordembeddings/lib/python3.5/site-packages\n",
      "gensim installed\n",
      "TensorFlow version: \t1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "import numpy\n",
    "import gensim\n",
    "import logging\n",
    "import sys, os\n",
    "import nltk\n",
    "import re, string, unicodedata\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time  # To time our operations\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "# */site-packages is where your current session is running its python out of\n",
    "site_path = ''\n",
    "for path in sys.path:\n",
    "    if 'site-packages' in path.split('/')[-1]:\n",
    "        print(path)\n",
    "        site_path = path\n",
    "# search to see if gensim in installed packages\n",
    "if len(site_path) > 0:\n",
    "    if not 'gensim' in os.listdir(site_path):\n",
    "        print('package not found')\n",
    "    else:\n",
    "        print('gensim installed')    \n",
    "        \n",
    "\n",
    "# Checking tensorflow installation\n",
    "print('TensorFlow version: \\t%s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining directories for reading text files and saving checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For displaying gensim logs\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Directory with raw txt-files\n",
    "TEXT_DIR  = 'Train/'\n",
    "\n",
    "# Directory for saving checkpoint and metadata\n",
    "MODEL_DIR = 'Checkpoints/'\n",
    "\n",
    "# Word2vec\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading all the text files in the corpus and tokeniztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    \"\"\"\n",
    "    Read in text files\n",
    "    \"\"\"\n",
    "    documents = list()\n",
    "    tokenize  = lambda x: simple_preprocess(x)\n",
    "    \n",
    "    # Read in all files in directory\n",
    "    if os.path.isdir(path):\n",
    "        for filename in os.listdir(path):\n",
    "            with open('%s/%s' % (path, filename), encoding='utf-8') as f:\n",
    "                doc = f.read()\n",
    "                doc = clean_doc(doc)\n",
    "                documents.append(tokenize(doc))\n",
    "    return documents\n",
    "\n",
    "def clean_doc(doc):\n",
    "    \"\"\"\n",
    "    Cleaning a document by several methods\n",
    "    \"\"\"\n",
    "    #doing basic cleaning\n",
    "    doc = re.sub(r'\\-+', '.', doc)\n",
    "    doc = re.sub(r'\\=+', '', doc)\n",
    "    doc = re.sub(r'\\(+', '', doc)\n",
    "    doc = re.sub(r'\\)+', '', doc)\n",
    "    # Lowercase\n",
    "    doc = doc.lower()\n",
    "    #Replace fullstop with token to train on\n",
    "    doc = doc.replace('.', ' __PERIOD__ ')\n",
    "    # Remove numbers\n",
    "    doc = re.sub(r\"[0-9]+\", \"__NUMBER__\", doc)\n",
    "    # Remove ' and full stops and brackets\n",
    "    doc = re.sub(r'[{}()\\']', '', doc)\n",
    "    #Remove other special characters\n",
    "    doc = re.sub(r'[;,:-@#]', '', doc)\n",
    "    # Split in tokens\n",
    "    tokens = doc.split()\n",
    "    # Tokens with less then two characters will be ignored\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 13848\n"
     ]
    }
   ],
   "source": [
    "docs = read_files(TEXT_DIR)\n",
    "print('Number of documents: %i' % len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training our Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the necessary hyperparameteres to tunr our word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now defining and training our Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : PROGRESS: at sentence #10000, processed 34394597 words, keeping 48456 word types\n",
      "INFO : collected 52587 word types from a corpus of 47086854 raw words and 13848 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : effective_min_count=5 retains 28021 unique words (53% of original 52587, drops 24566)\n",
      "INFO : effective_min_count=5 leaves 47040002 word corpus (99% of original 47086854, drops 46852)\n",
      "INFO : deleting the raw counts dictionary of 52587 items\n",
      "INFO : sample=0.001 downsamples 59 most-common words\n",
      "INFO : downsampling leaves estimated 34921007 word corpus (74.2% of prior 47040002)\n",
      "INFO : estimated required memory for 28021 words and 300 dimensions: 81260900 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 3 workers on 28021 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO : EPOCH 1 - PROGRESS: at 2.77% examples, 840847 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 5.49% examples, 869251 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 8.57% examples, 882294 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 10.90% examples, 844797 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 13.79% examples, 856893 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 16.71% examples, 861831 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 19.62% examples, 872353 words/s, in_qsize 4, out_qsize 1\n",
      "INFO : EPOCH 1 - PROGRESS: at 22.38% examples, 875934 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 25.57% examples, 881115 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 28.83% examples, 883050 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 31.87% examples, 886568 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 34.91% examples, 887540 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 37.93% examples, 890990 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 40.85% examples, 893005 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 43.71% examples, 891184 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 46.66% examples, 892212 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 49.94% examples, 894618 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 52.53% examples, 889013 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 55.49% examples, 890441 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 58.41% examples, 891835 words/s, in_qsize 4, out_qsize 2\n",
      "INFO : EPOCH 1 - PROGRESS: at 61.46% examples, 893930 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 64.54% examples, 894931 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 67.68% examples, 897464 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 70.65% examples, 897756 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 73.52% examples, 898784 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 76.19% examples, 894918 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 79.20% examples, 896208 words/s, in_qsize 4, out_qsize 1\n",
      "INFO : EPOCH 1 - PROGRESS: at 82.33% examples, 896967 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 85.50% examples, 897395 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 88.33% examples, 897942 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 90.81% examples, 893380 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 94.09% examples, 894054 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 96.69% examples, 889511 words/s, in_qsize 4, out_qsize 1\n",
      "INFO : EPOCH 1 - PROGRESS: at 99.62% examples, 888306 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 47086854 raw words (30483089 effective words) took 34.3s, 888774 effective words/s\n",
      "INFO : EPOCH 2 - PROGRESS: at 2.99% examples, 914591 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 5.89% examples, 943280 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 9.14% examples, 943336 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 12.18% examples, 942733 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 15.22% examples, 940049 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 18.26% examples, 943062 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 20.94% examples, 939628 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 24.13% examples, 943089 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 26.95% examples, 927635 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 30.27% examples, 929239 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 32.91% examples, 916222 words/s, in_qsize 5, out_qsize 1\n",
      "INFO : EPOCH 2 - PROGRESS: at 35.36% examples, 901755 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 38.45% examples, 905562 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 41.53% examples, 908718 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 44.55% examples, 910869 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 47.88% examples, 913263 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 51.13% examples, 914898 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 54.15% examples, 916978 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 56.96% examples, 917707 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 60.33% examples, 919547 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 63.22% examples, 919999 words/s, in_qsize 6, out_qsize 1\n",
      "INFO : EPOCH 2 - PROGRESS: at 66.49% examples, 922809 words/s, in_qsize 4, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 69.49% examples, 922303 words/s, in_qsize 5, out_qsize 1\n",
      "INFO : EPOCH 2 - PROGRESS: at 72.56% examples, 924387 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 75.77% examples, 925143 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 78.60% examples, 925494 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 81.88% examples, 926484 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 84.52% examples, 920023 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 87.14% examples, 914007 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 89.66% examples, 911884 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 93.07% examples, 913563 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 96.17% examples, 913373 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 99.56% examples, 915385 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 47086854 raw words (30488536 effective words) took 33.3s, 915660 effective words/s\n",
      "INFO : EPOCH 3 - PROGRESS: at 2.99% examples, 898474 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 5.25% examples, 817247 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 7.55% examples, 795734 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 10.21% examples, 780651 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 12.94% examples, 804231 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 16.09% examples, 828020 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 19.11% examples, 845523 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 21.90% examples, 857979 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 25.19% examples, 868782 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 28.44% examples, 872621 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH 3 - PROGRESS: at 31.51% examples, 879949 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 34.79% examples, 883664 words/s, in_qsize 5, out_qsize 1\n",
      "INFO : EPOCH 3 - PROGRESS: at 37.88% examples, 889356 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 40.89% examples, 893364 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 43.95% examples, 896566 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 47.09% examples, 898655 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 50.26% examples, 899469 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 53.47% examples, 901873 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 56.28% examples, 904644 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 59.51% examples, 906299 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 62.61% examples, 908268 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 65.55% examples, 909575 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 68.79% examples, 911762 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 71.83% examples, 912129 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 75.09% examples, 914663 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 77.82% examples, 914041 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 80.91% examples, 914945 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 84.29% examples, 915056 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 87.33% examples, 915163 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 90.22% examples, 915780 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 93.64% examples, 916794 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 96.79% examples, 917223 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 99.43% examples, 911636 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 47086854 raw words (30488469 effective words) took 33.5s, 910643 effective words/s\n",
      "INFO : EPOCH 4 - PROGRESS: at 3.08% examples, 942664 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 5.82% examples, 940941 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 9.14% examples, 948110 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 12.07% examples, 938449 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 15.24% examples, 944484 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 18.18% examples, 941321 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 20.98% examples, 943371 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 24.13% examples, 944527 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 27.44% examples, 943330 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 30.21% examples, 929586 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 32.77% examples, 912941 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 35.17% examples, 898196 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 37.72% examples, 887070 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 40.50% examples, 887654 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 43.67% examples, 892076 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 46.64% examples, 893341 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 50.01% examples, 897505 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 53.14% examples, 898377 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 55.97% examples, 901219 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 59.12% examples, 902390 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 62.15% examples, 904146 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 65.11% examples, 905778 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 68.15% examples, 905283 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 71.30% examples, 907022 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 74.35% examples, 907712 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 77.34% examples, 909191 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 80.21% examples, 909675 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 83.78% examples, 911374 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 86.86% examples, 911383 words/s, in_qsize 6, out_qsize 2\n",
      "INFO : EPOCH 4 - PROGRESS: at 89.64% examples, 911079 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 92.91% examples, 911936 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 96.09% examples, 912246 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 99.41% examples, 913216 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 47086854 raw words (30485717 effective words) took 33.4s, 913595 effective words/s\n",
      "INFO : EPOCH 5 - PROGRESS: at 2.60% examples, 791331 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 5.26% examples, 830264 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 8.42% examples, 862829 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 11.37% examples, 876182 words/s, in_qsize 6, out_qsize 1\n",
      "INFO : EPOCH 5 - PROGRESS: at 14.31% examples, 888640 words/s, in_qsize 5, out_qsize 1\n",
      "INFO : EPOCH 5 - PROGRESS: at 17.32% examples, 891991 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 20.16% examples, 901157 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 23.00% examples, 901990 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 26.32% examples, 905876 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 29.45% examples, 904190 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 32.57% examples, 907553 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 35.58% examples, 907917 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 38.63% examples, 909572 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 41.55% examples, 909630 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 44.54% examples, 910622 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 47.76% examples, 910969 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 50.94% examples, 911305 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 53.83% examples, 909330 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 56.39% examples, 906774 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 58.74% examples, 897437 words/s, in_qsize 6, out_qsize 1\n",
      "INFO : EPOCH 5 - PROGRESS: at 61.34% examples, 891118 words/s, in_qsize 4, out_qsize 1\n",
      "INFO : EPOCH 5 - PROGRESS: at 64.13% examples, 891063 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 67.37% examples, 893375 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 69.97% examples, 888872 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 72.92% examples, 891323 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 75.90% examples, 892127 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 78.78% examples, 892763 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 81.89% examples, 893736 words/s, in_qsize 4, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 85.24% examples, 894743 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 87.98% examples, 894162 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 90.87% examples, 894608 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 94.17% examples, 895412 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH 5 - PROGRESS: at 97.33% examples, 895535 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 47086854 raw words (30489151 effective words) took 34.0s, 896810 effective words/s\n",
      "INFO : training on a 235434270 raw words (152434962 effective words) took 168.5s, 904865 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(docs, size=EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our trained model as a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : saving Word2Vec object under Checkpoints/word2vec, separately None\n",
      "INFO : not storing attribute vectors_norm\n",
      "INFO : not storing attribute cum_table\n",
      "INFO : saved Checkpoints/word2vec\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "model.save(os.path.join(MODEL_DIR,'word2vec'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating metadata and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of weights: (28021, 300)\n",
      "Vocabulary size: 28021\n",
      "Embedding size: 300\n"
     ]
    }
   ],
   "source": [
    "weights     = model.wv.vectors\n",
    "index_words = model.wv.index2word\n",
    "\n",
    "vocab_size    = weights.shape[0]\n",
    "embedding_dim = weights.shape[1]\n",
    "\n",
    "print('Shape of weights:', weights.shape)\n",
    "print('Vocabulary size: %i' % vocab_size)\n",
    "print('Embedding size: %i'  % embedding_dim)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR,'metadata.tsv'), 'w') as f:\n",
    "    f.writelines(\"\\n\".join(index_words))\n",
    "\n",
    "# Required if you re-run without restarting the kernel\n",
    "tf.reset_default_graph()\n",
    "    \n",
    "W = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]), trainable=False, name=\"W\")\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n",
    "\n",
    "embedding_init = W.assign(embedding_placeholder)\n",
    "writer = tf.summary.FileWriter(MODEL_DIR, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = W.name\n",
    "embedding.metadata_path = './metadata.tsv'\n",
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(embedding_init, feed_dict={embedding_placeholder: weights})\n",
    "    save_path = saver.save(sess, os.path.join(MODEL_DIR, \"model.cpkt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rate', 0.38391363620758057),\n",
       " ('counterparty', 0.3482518196105957),\n",
       " ('credit', 0.3377344012260437),\n",
       " ('notionalamount', 0.32945629954338074),\n",
       " ('default', 0.31928637623786926),\n",
       " ('levelsfair', 0.3183319568634033),\n",
       " ('spread', 0.31472811102867126),\n",
       " ('thenotional', 0.3118211030960083),\n",
       " ('longnotional', 0.2922995686531067),\n",
       " ('face', 0.286532461643219)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['notional'], topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
