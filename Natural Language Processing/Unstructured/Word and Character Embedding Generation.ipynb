{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/vvsaripalli/SECReports/Understanding-Financial-Reports-using-Natural-Language-Processing/Natural Language Processing/wordembeddings/lib/python3.5/site-packages\n",
      "gensim installed\n",
      "TensorFlow version: \t1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "import numpy\n",
    "import gensim\n",
    "import logging\n",
    "import sys, os\n",
    "import nltk\n",
    "import re, string, unicodedata\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time  # To time our operations\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "# */site-packages is where your current session is running its python out of\n",
    "site_path = ''\n",
    "for path in sys.path:\n",
    "    if 'site-packages' in path.split('/')[-1]:\n",
    "        print(path)\n",
    "        site_path = path\n",
    "# search to see if gensim in installed packages\n",
    "if len(site_path) > 0:\n",
    "    if not 'gensim' in os.listdir(site_path):\n",
    "        print('package not found')\n",
    "    else:\n",
    "        print('gensim installed')    \n",
    "        \n",
    "\n",
    "# Checking tensorflow installation\n",
    "print('TensorFlow version: \\t%s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining directories for reading text files and saving checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For displaying gensim logs\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Directory with raw txt-files\n",
    "TEXT_DIR  = 'Train/'\n",
    "\n",
    "# Directory for saving checkpoint and metadata\n",
    "MODEL_DIR = 'Checkpoints/'\n",
    "\n",
    "# Word2vec\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading all the text files in the corpus and tokeniztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    \"\"\"\n",
    "    Read in text files\n",
    "    \"\"\"\n",
    "    documents = list()\n",
    "    tokenize  = lambda x: simple_preprocess(x)\n",
    "    \n",
    "    # Read in all files in directory\n",
    "    if os.path.isdir(path):\n",
    "        for filename in os.listdir(path):\n",
    "            with open('%s/%s' % (path, filename), encoding='utf-8') as f:\n",
    "                doc = f.read()\n",
    "                doc = clean_doc(doc)\n",
    "                documents.append(tokenize(doc))\n",
    "    return documents\n",
    "\n",
    "def clean_doc(doc):\n",
    "    \"\"\"\n",
    "    Cleaning a document by several methods\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    doc = doc.lower()\n",
    "    # Remove numbers\n",
    "    doc = re.sub(r\"[0-9]+\", \"\", doc)\n",
    "    # Split in tokens\n",
    "    tokens = doc.split()\n",
    "    # Remove punctuation\n",
    "    tokens = [w.translate(str.maketrans('', '', string.punctuation)) for w in tokens]\n",
    "    # Tokens with less then two characters will be ignored\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10179\n"
     ]
    }
   ],
   "source": [
    "docs = read_files(TEXT_DIR)\n",
    "print('Number of documents: %i' % len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training our Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the necessary hyperparameteres to tunr our word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now defining and training our Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : PROGRESS: at sentence #10000, processed 41307242 words, keeping 49666 word types\n",
      "INFO : collected 49818 word types from a corpus of 42010610 raw words and 10179 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : effective_min_count=5 retains 26611 unique words (53% of original 49818, drops 23207)\n",
      "INFO : effective_min_count=5 leaves 41965734 word corpus (99% of original 42010610, drops 44876)\n",
      "INFO : deleting the raw counts dictionary of 49818 items\n",
      "INFO : sample=0.001 downsamples 59 most-common words\n",
      "INFO : downsampling leaves estimated 31084159 word corpus (74.1% of prior 41965734)\n",
      "INFO : estimated required memory for 26611 words and 300 dimensions: 77171900 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 3 workers on 26611 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO : EPOCH 1 - PROGRESS: at 3.16% examples, 857388 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 6.43% examples, 878761 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 9.76% examples, 883593 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 13.10% examples, 899006 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 16.27% examples, 887154 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 19.51% examples, 897923 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 22.85% examples, 902358 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 26.61% examples, 908743 words/s, in_qsize 6, out_qsize 1\n",
      "INFO : EPOCH 1 - PROGRESS: at 30.27% examples, 912785 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 33.82% examples, 915022 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 37.25% examples, 916647 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 40.60% examples, 918631 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 43.95% examples, 919423 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 47.61% examples, 920414 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 51.27% examples, 921726 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 54.61% examples, 921430 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 57.98% examples, 922796 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 61.24% examples, 923206 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 64.28% examples, 917269 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 67.55% examples, 914273 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 71.37% examples, 917113 words/s, in_qsize 5, out_qsize 1\n",
      "INFO : EPOCH 1 - PROGRESS: at 75.11% examples, 919539 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 77.97% examples, 913852 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 81.30% examples, 914213 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 84.92% examples, 915013 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 88.29% examples, 916620 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 91.92% examples, 917295 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 95.68% examples, 918178 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 1 - PROGRESS: at 98.59% examples, 912041 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 42010610 raw words (26945623 effective words) took 29.5s, 912865 effective words/s\n",
      "INFO : EPOCH 2 - PROGRESS: at 3.49% examples, 933932 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 6.87% examples, 953148 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 10.56% examples, 952420 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 13.98% examples, 955045 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 17.40% examples, 956901 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 20.65% examples, 957096 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 24.26% examples, 955539 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 27.58% examples, 940780 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 30.45% examples, 916761 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 33.79% examples, 913095 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 37.26% examples, 915719 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 40.84% examples, 921429 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 922264 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 47.99% examples, 926174 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 51.57% examples, 926901 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 55.16% examples, 929603 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 58.51% examples, 930726 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 61.94% examples, 932587 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 65.55% examples, 934437 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 69.23% examples, 934865 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 72.65% examples, 934266 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 76.47% examples, 936840 words/s, in_qsize 4, out_qsize 1\n",
      "INFO : EPOCH 2 - PROGRESS: at 80.01% examples, 939911 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 84.00% examples, 942151 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 87.60% examples, 944486 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 91.25% examples, 947035 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 95.24% examples, 948413 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 2 - PROGRESS: at 99.21% examples, 949431 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 42010610 raw words (26945968 effective words) took 28.4s, 950013 effective words/s\n",
      "INFO : EPOCH 3 - PROGRESS: at 3.81% examples, 1009608 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 7.22% examples, 994061 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 10.69% examples, 968987 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 14.12% examples, 966089 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 17.55% examples, 965419 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 20.78% examples, 964189 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 24.41% examples, 965051 words/s, in_qsize 3, out_qsize 1\n",
      "INFO : EPOCH 3 - PROGRESS: at 28.34% examples, 960774 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 32.08% examples, 963041 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 35.54% examples, 962201 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 39.31% examples, 964165 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 42.63% examples, 962546 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 46.08% examples, 961688 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 49.82% examples, 961047 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 53.40% examples, 957750 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 56.56% examples, 955789 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 60.02% examples, 955002 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 63.48% examples, 955600 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 67.17% examples, 954993 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 70.82% examples, 955165 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH 3 - PROGRESS: at 74.52% examples, 954610 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 77.99% examples, 954682 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 81.39% examples, 954330 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 85.20% examples, 954739 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 88.56% examples, 955087 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 92.19% examples, 954551 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 96.10% examples, 954133 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 3 - PROGRESS: at 99.66% examples, 954276 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 42010610 raw words (26942845 effective words) took 28.2s, 954436 effective words/s\n",
      "INFO : EPOCH 4 - PROGRESS: at 3.55% examples, 949160 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 6.83% examples, 947098 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 10.49% examples, 946534 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 13.51% examples, 924093 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 16.19% examples, 884547 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 19.47% examples, 899818 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 22.90% examples, 908763 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 26.63% examples, 913623 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 30.37% examples, 917661 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 33.88% examples, 919888 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 37.44% examples, 923898 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 40.84% examples, 924879 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 43.86% examples, 918578 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 46.98% examples, 912667 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 50.37% examples, 910045 words/s, in_qsize 5, out_qsize 1\n",
      "INFO : EPOCH 4 - PROGRESS: at 53.91% examples, 910596 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 56.73% examples, 904465 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 60.35% examples, 906924 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 63.51% examples, 907925 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 67.23% examples, 909703 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 70.68% examples, 909588 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 74.41% examples, 911865 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 77.74% examples, 911620 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 81.30% examples, 914302 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 84.10% examples, 906431 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 87.52% examples, 907022 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 90.84% examples, 907364 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 94.63% examples, 909282 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 4 - PROGRESS: at 98.48% examples, 910174 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 42010610 raw words (26944316 effective words) took 29.6s, 910772 effective words/s\n",
      "INFO : EPOCH 5 - PROGRESS: at 3.21% examples, 871618 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 6.71% examples, 917115 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 10.25% examples, 918560 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 13.66% examples, 931445 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 16.73% examples, 917884 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 20.06% examples, 924863 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 23.45% examples, 926262 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 27.03% examples, 926656 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 30.68% examples, 928767 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 34.38% examples, 931426 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 37.57% examples, 925974 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 41.05% examples, 927689 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 44.34% examples, 926304 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 48.08% examples, 929571 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 51.69% examples, 931084 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 55.22% examples, 931825 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 58.63% examples, 934187 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 61.94% examples, 933345 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 65.28% examples, 931547 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 68.52% examples, 927032 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 71.61% examples, 919020 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 74.98% examples, 918102 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 78.29% examples, 918831 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 81.56% examples, 917580 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 85.20% examples, 917432 words/s, in_qsize 6, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 88.42% examples, 917961 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 91.96% examples, 917800 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 95.72% examples, 918290 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : EPOCH 5 - PROGRESS: at 99.36% examples, 918039 words/s, in_qsize 5, out_qsize 0\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 42010610 raw words (26943533 effective words) took 29.3s, 918382 effective words/s\n",
      "INFO : training on a 210053050 raw words (134722285 effective words) took 145.1s, 928685 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(docs, size=EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our trained model as a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : saving Word2Vec object under Checkpoints/word2vec, separately None\n",
      "INFO : not storing attribute vectors_norm\n",
      "INFO : not storing attribute cum_table\n",
      "INFO : saved Checkpoints/word2vec\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "model.save(os.path.join(MODEL_DIR,'word2vec'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating metadata and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of weights: (26611, 300)\n",
      "Vocabulary size: 26611\n",
      "Embedding size: 300\n"
     ]
    }
   ],
   "source": [
    "weights     = model.wv.vectors\n",
    "index_words = model.wv.index2word\n",
    "\n",
    "vocab_size    = weights.shape[0]\n",
    "embedding_dim = weights.shape[1]\n",
    "\n",
    "print('Shape of weights:', weights.shape)\n",
    "print('Vocabulary size: %i' % vocab_size)\n",
    "print('Embedding size: %i'  % embedding_dim)\n",
    "\n",
    "with open(os.path.join(MODEL_DIR,'metadata.tsv'), 'w') as f:\n",
    "    f.writelines(\"\\n\".join(index_words))\n",
    "\n",
    "# Required if you re-run without restarting the kernel\n",
    "tf.reset_default_graph()\n",
    "    \n",
    "W = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]), trainable=False, name=\"W\")\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n",
    "\n",
    "embedding_init = W.assign(embedding_placeholder)\n",
    "writer = tf.summary.FileWriter(MODEL_DIR, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = W.name\n",
    "embedding.metadata_path = './metadata.tsv'\n",
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(embedding_init, feed_dict={embedding_placeholder: weights})\n",
    "    save_path = saver.save(sess, os.path.join(MODEL_DIR, \"model.cpkt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rate', 0.36345726251602173),\n",
       " ('notionalamount', 0.3470466434955597),\n",
       " ('credit', 0.3354322612285614),\n",
       " ('counterparty', 0.33380112051963806),\n",
       " ('spread', 0.31705808639526367),\n",
       " ('thenotional', 0.30927133560180664),\n",
       " ('default', 0.3026345372200012),\n",
       " ('face', 0.2952166199684143),\n",
       " ('usd', 0.294778972864151),\n",
       " ('notionalbalance', 0.28938454389572144)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['notional'], topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
