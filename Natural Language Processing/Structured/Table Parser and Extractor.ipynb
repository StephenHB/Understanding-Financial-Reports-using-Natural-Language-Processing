{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to extract all the possible tables from the structured and unstructured SEC filings with minimal use of RegEx and try to aggregate all the tables which may or may not contain CDS information. Once that is comepletely, filtering method should be in place which would filter out the tables which do not have Credit Default Swap information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring libraries required to run our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4 import NavigableString\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "\n",
    "import pprint\n",
    "import csv\n",
    "import urllib\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and reading program arguments to extract filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_name = sys.argv[0]\n",
    "arguments = sys.argv[1:]\n",
    "count = len(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the get table functions and supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tables(soup, counter):\n",
    "    \"\"\"\n",
    "    Extracts each table on the page and places it in a dictionary.\n",
    "    Converts each dictionary to a Table object. Returns a list of\n",
    "    pointers to the respective Table object(s).\n",
    "    \"\"\"\n",
    "    table_list = []\n",
    "    for iterator in range(1, counter):\n",
    "        # Find the first <p> tag with the search text and class\n",
    "        table_tag = soup.find(\"p\", {\"class\": str(iterator)})\n",
    "        # Find the first <table> tag that follows it\n",
    "        table = table_tag.findNext(\"table\")\n",
    "        # empty dictionary each time represents our table\n",
    "        table_dict = {}\n",
    "        rows = table.findAll(\"tr\")\n",
    "        # count will be the key for each list of values\n",
    "        count = 0\n",
    "        for row in rows:\n",
    "            value_list = []\n",
    "            entries = row.findAll(\"td\")\n",
    "            for entry in entries:\n",
    "                # fix the encoding issues with utf-8\n",
    "                entry = entry.text.encode(\"utf-8\", \"ignore\")\n",
    "                strip_unicode = re.compile(\n",
    "                    \"([^-_a-zA-Z0-9!@#%&=,/'\\\";:~`\\$\\^\\*\\(\\)\\+\\[\\]\\.\\{\\}\\|\\?\\<\\>\\\\]+|[^\\s]+)\")\n",
    "                entry = entry.decode(\"utf-8\")\n",
    "                entry = strip_unicode.sub(\" \", entry)\n",
    "                value_list.append(entry)\n",
    "            # we don't want empty data packages\n",
    "            if len(value_list) > 0:\n",
    "                table_dict[count] = value_list\n",
    "                count += 1\n",
    "\n",
    "        table_obj = Table(table_dict)\n",
    "        table_list.append(table_obj)\n",
    "\n",
    "    return table_list\n",
    "\n",
    "\n",
    "def append_classID(filepath):\n",
    "    # Reading Files\n",
    "    f = open(filepath, 'r')\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # Making soup\n",
    "    soup = bs(data, \"lxml\")\n",
    "    searchtext = \"Credit Default\"\n",
    "\n",
    "    all_tags = []\n",
    "    counter = 0\n",
    "    # Find the first <p> tag with the search text\n",
    "    all_tags = soup.find_all(\"p\")\n",
    "    lengthFoundText = len(all_tags)\n",
    "    for i in range(lengthFoundText):\n",
    "        if searchtext in all_tags[i].text:\n",
    "            counter += 1\n",
    "            all_tags[i]['class'] = counter\n",
    "\n",
    "    return soup, counter\n",
    "\n",
    "\n",
    "def save_tables(tables):\n",
    "    \"\"\"\n",
    "    Takes an input a list of table objects and saves each\n",
    "    table to csv format.\n",
    "    \"\"\"\n",
    "    counter = 1\n",
    "    for table in tables:\n",
    "        name = \"table\" + str(counter)\n",
    "        table.save_table(name)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining table function to get the table data and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Metadata = namedtuple(\"Metadata\", \"num_cols num_entries\")\n",
    "\n",
    "\n",
    "class Table:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Stores a given table as a dictionary. The keys are the headings and the\n",
    "        values are the data, represented as lists.\n",
    "        \"\"\"\n",
    "        self.table_data = data\n",
    "\n",
    "    def get_metadata(self):\n",
    "        \"\"\"\n",
    "        Returns a Metadata object that contains the number of columns\n",
    "        and the total number of entries.\n",
    "        \"\"\"\n",
    "\n",
    "        col_headings = self.table_data.keys()\n",
    "        num_cols = len(col_headings)\n",
    "        num_entries = 0\n",
    "\n",
    "        for heading in col_headings:\n",
    "            num_entries += len(self.table_data[heading])\n",
    "\n",
    "        return Metadata(\n",
    "            num_cols=num_cols,\n",
    "            num_entries=num_entries\n",
    "        )\n",
    "\n",
    "    def save_table(self, name):\n",
    "        \"\"\"\n",
    "        Saves a table to csv format under the given file name.\n",
    "        File name should omit the extension.\n",
    "        \"\"\"\n",
    "        fname = name + \".csv\"\n",
    "\n",
    "        with open(fname, 'w', encoding='utf8') as outf:\n",
    "            w = csv.writer(outf, dialect=\"excel\")\n",
    "            li = self.table_data.values()\n",
    "            w.writerows(li)\n",
    "\n",
    "    def show_table(self):\n",
    "        \"\"\"\n",
    "        Prints a formatted table to the command line using pprint\n",
    "        \"\"\"\n",
    "        pprint.pprint(self.table_data, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making the soup.........\n",
      "Soup is ready.........\n",
      "got the tables.......\n",
      "tables saved.......\n"
     ]
    }
   ],
   "source": [
    "#Initiate the start time of the program\n",
    "start = time.time()\n",
    "\n",
    "# Read the filepath\n",
    "program_name = arguments[0]\n",
    "\n",
    "#Souping\n",
    "print(\"making the soup.........\")\n",
    "soup, length = append_classID(program_name)\n",
    "print(\"Soup is ready.........\")\n",
    "\n",
    "# get the tables\n",
    "tables = get_tables(soup, length)\n",
    "print(\"got the tables.......\")\n",
    "\n",
    "# save the tables\n",
    "save_tables(tables)\n",
    "print(\"tables saved.......\")\n",
    "\n",
    "# Printing time taken\n",
    "end = time.time()\n",
    "print(\"The total time taken for CDS tables extraction is: \", end - start, \"s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
